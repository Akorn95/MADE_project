{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b2430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import unidecode\n",
    "import re\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import spacy\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import gensim.downloader as api\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "def vectorize(list_of_docs, model):\n",
    "    features = []\n",
    "\n",
    "    for tokens in list_of_docs:\n",
    "        zero_vector = np.zeros(model.vector_size)\n",
    "        vectors = []\n",
    "        for token, cnt in Counter(tokens).items():\n",
    "            if token in model and len(token)>2 and cnt >2:\n",
    "                try:\n",
    "                    vectors.append(model[token])\n",
    "                except KeyError:\n",
    "                    continue\n",
    "        if vectors:\n",
    "            vectors = np.asarray(vectors)\n",
    "            avg_vec = vectors.mean(axis=0)\n",
    "            features.append(avg_vec.tolist())\n",
    "        else:\n",
    "            features.append(zero_vector)\n",
    "    return features\n",
    "\n",
    "def project_data_preparation(text, wv):\n",
    "    data = df[:100]['text']\n",
    "    reg = re.compile('[^a-zA-Z ]')\n",
    "    data=data.apply(lambda x: ' '.join(reg.sub(' ', unidecode.unidecode(str(x))).lower().strip().split()))\n",
    "    my_stop = stopwords.words('english')+['article', 'page', 'papper', 'abstract'\n",
    "                                      , 't', 's', 'by', 'awarded', 'conference', 'will', 'of', 'for', 'problem']\n",
    "    sp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "    data = data.apply(lambda x:  [w.lemma_ for w in sp(x) if (w.text not in my_stop)])\n",
    "    vectorize(data, wv)\n",
    "    return vectorize(data, wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31779eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "import gensim \n",
    "\n",
    "import itertools\n",
    "\n",
    "\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa60cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de24795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spacy.cli.download(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29655b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['d2v_sp'] = vectorize(df['sp'], wv)\n",
    "df['sum'] = df['d2v_sp'].apply(lambda x: sum(x))\n",
    "df_droped=df[df['sum'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eedc4f5",
   "metadata": {},
   "source": [
    "предобученный гугл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd7df5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cur_model = KMeans(n_clusters=24, random_state=42).fit(pd.DataFrame(df_droped['d2v_sp'].tolist()))\n",
    "for i in range(len(cur_model.cluster_centers_)):\n",
    "    print ('\\nClaster_'+str(i)+f\": {np.unique(cur_model.labels_, return_counts=True)[1][i]}\")\n",
    "    print(wv.similar_by_vector(cur_model.cluster_centers_[i], topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be56cc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_droped['label'] = cur_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48005f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
